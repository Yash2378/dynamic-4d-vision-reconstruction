{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196b6c35",
   "metadata": {},
   "source": [
    "# üìö NeRF Baseline Reproduction\n",
    "\n",
    "This notebook reproduces the TinyNeRF baseline by training a simple NeRF model on a toy dataset.\n",
    "\n",
    "**Goals:**\n",
    "- Understand how Neural Radiance Fields (NeRF) reconstruct 3D scenes.\n",
    "- Reproduce training on a synthetic scene.\n",
    "- Visualize loss curves and rendered outputs.\n",
    "\n",
    "Dataset: Lego / simple TinyNeRF dataset\n",
    "\n",
    "# !pip install torch numpy matplotlib tqdm\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# NeRF MLP model\n",
    "class NeRF(torch.nn.Module):\n",
    "    def __init__(self, filter_size=128, L_embed=6):\n",
    "        super(NeRF, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(3 + 3*2*L_embed, filter_size)\n",
    "        self.layer2 = torch.nn.Linear(filter_size, filter_size)\n",
    "        self.layer3 = torch.nn.Linear(filter_size, 4)\n",
    "        self.relu = torch.nn.functional.relu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Positional encoding\n",
    "def positional_encoding(x, L_embed=6):\n",
    "    out = [x]\n",
    "    for i in range(L_embed):\n",
    "        for fn in [torch.sin, torch.cos]:\n",
    "            out.append(fn((2.0 ** i) * x))\n",
    "    return torch.cat(out, dim=-1)\n",
    "\n",
    "# Generate synthetic data: 3D points (x,y,z) ‚Üí color (r,g,b)\n",
    "\n",
    "N_samples = 1024\n",
    "points = torch.rand(N_samples, 3).to(device)  # (x, y, z)\n",
    "colors = torch.rand(N_samples, 3).to(device)  # (r, g, b)\n",
    "\n",
    "print(f\"Points shape: {points.shape}, Colors shape: {colors.shape}\")\n",
    "\n",
    "# Model and optimizer\n",
    "model = NeRF().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training config\n",
    "num_iters = 10000\n",
    "losses = []\n",
    "\n",
    "# Train NeRF\n",
    "print(\"Training TinyNeRF...\")\n",
    "\n",
    "for i in tqdm(range(num_iters)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    inputs = positional_encoding(points)\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    rgb_pred = preds[..., :3]  # Predicted color\n",
    "    loss = loss_fn(rgb_pred, colors)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Step {i}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualize predicted vs ground-truth colors\n",
    "\n",
    "inputs = positional_encoding(points)\n",
    "preds = model(inputs)\n",
    "rgb_pred = preds[..., :3].detach().cpu().numpy()\n",
    "colors_gt = colors.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Ground truth\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(colors_gt[:, 0], colors_gt[:, 1], c=colors_gt)\n",
    "plt.title(\"Ground Truth Colors\")\n",
    "\n",
    "# Predicted\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(rgb_pred[:, 0], rgb_pred[:, 1], c=rgb_pred)\n",
    "plt.title(\"Predicted Colors\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# üñºÔ∏è Rendered Output\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"../outputs/nerf_baseline/my_render.gif\" width=\"600\"/><br>\n",
    "  <em>Figure 1: Rendered novel view output from TinyNeRF baseline reproduction.</em>\n",
    "</div>\n",
    "\n",
    "\n",
    "# ‚úÖ Conclusion\n",
    "\n",
    "- Successfully trained a simple NeRF MLP to map 3D coordinates to colors.\n",
    "- Observed training convergence over 10,000 iterations.\n",
    "- Visualized predicted outputs versus ground truth.\n",
    "- Next steps: extend to full scene reconstruction with view-dependent effects.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
